<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - doc-coverage.info - rapid-classification-ai-trainer/plugins/classificationplugins/mmclassificationplugin/mmclassification_test.py</title>
  <link rel="stylesheet" type="text/css" href="../../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../../index.html">top level</a> - <a href="index.html">rapid-classification-ai-trainer/plugins/classificationplugins/mmclassificationplugin</a> - mmclassification_test.py</td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">doc-coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">3</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-09-06 03:30:40</td>
            <td></td>
          </tr>
          <tr><td><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span><span class="lineNoCov">          0 : import argparse</span></a>
<a name="2"><span class="lineNum">       2 </span>            : import os</a>
<a name="3"><span class="lineNum">       3 </span>            : import warnings</a>
<a name="4"><span class="lineNum">       4 </span>            : </a>
<a name="5"><span class="lineNum">       5 </span>            : import mmcv</a>
<a name="6"><span class="lineNum">       6 </span>            : import numpy as np</a>
<a name="7"><span class="lineNum">       7 </span>            : import torch</a>
<a name="8"><span class="lineNum">       8 </span>            : from mmcv import DictAction</a>
<a name="9"><span class="lineNum">       9 </span>            : from mmcv.parallel import MMDataParallel, MMDistributedDataParallel</a>
<a name="10"><span class="lineNum">      10 </span>            : from mmcv.runner import get_dist_info, init_dist, load_checkpoint</a>
<a name="11"><span class="lineNum">      11 </span>            : </a>
<a name="12"><span class="lineNum">      12 </span>            : from mmcls.apis import multi_gpu_test, single_gpu_test</a>
<a name="13"><span class="lineNum">      13 </span>            : from mmcls.datasets import build_dataloader, build_dataset</a>
<a name="14"><span class="lineNum">      14 </span>            : from mmcls.models import build_classifier</a>
<a name="15"><span class="lineNum">      15 </span>            : </a>
<a name="16"><span class="lineNum">      16 </span>            : import json</a>
<a name="17"><span class="lineNum">      17 </span>            : </a>
<a name="18"><span class="lineNum">      18 </span>            : # TODO import `wrap_fp16_model` from mmcv and delete them from mmcls</a>
<a name="19"><span class="lineNum">      19 </span>            : try:</a>
<a name="20"><span class="lineNum">      20 </span>            :     from mmcv.runner import wrap_fp16_model</a>
<a name="21"><span class="lineNum">      21 </span>            : except ImportError:</a>
<a name="22"><span class="lineNum">      22 </span>            :     warnings.warn('wrap_fp16_model from mmcls will be deprecated.'</a>
<a name="23"><span class="lineNum">      23 </span>            :                   'Please install mmcv&gt;=1.1.4.')</a>
<a name="24"><span class="lineNum">      24 </span>            :     from mmcls.core import wrap_fp16_model</a>
<a name="25"><span class="lineNum">      25 </span>            : </a>
<a name="26"><span class="lineNum">      26 </span>            : </a>
<a name="27"><span class="lineNum">      27 </span><span class="lineNoCov">          0 : def parse_args():</span></a>
<a name="28"><span class="lineNum">      28 </span>            :     parser = argparse.ArgumentParser(description='mmcls test model')</a>
<a name="29"><span class="lineNum">      29 </span>            :     parser.add_argument('config', help='test config file path')</a>
<a name="30"><span class="lineNum">      30 </span>            :     parser.add_argument('checkpoint', help='checkpoint file')</a>
<a name="31"><span class="lineNum">      31 </span>            :     parser.add_argument('--out', help='output result file')</a>
<a name="32"><span class="lineNum">      32 </span>            :     parser.add_argument('--confidenceScoresOut', help='output file for confidence scores')</a>
<a name="33"><span class="lineNum">      33 </span>            :     parser.add_argument(</a>
<a name="34"><span class="lineNum">      34 </span>            :         '--metrics',</a>
<a name="35"><span class="lineNum">      35 </span>            :         type=str,</a>
<a name="36"><span class="lineNum">      36 </span>            :         nargs='+',</a>
<a name="37"><span class="lineNum">      37 </span>            :         help='evaluation metrics, which depends on the dataset, e.g., '</a>
<a name="38"><span class="lineNum">      38 </span>            :         '&quot;accuracy&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;f1_score&quot;, &quot;support&quot; for single '</a>
<a name="39"><span class="lineNum">      39 </span>            :         'label dataset, and &quot;mAP&quot;, &quot;CP&quot;, &quot;CR&quot;, &quot;CF1&quot;, &quot;OP&quot;, &quot;OR&quot;, &quot;OF1&quot; for '</a>
<a name="40"><span class="lineNum">      40 </span>            :         'multi-label dataset')</a>
<a name="41"><span class="lineNum">      41 </span>            :     parser.add_argument('--show', action='store_true', help='show results')</a>
<a name="42"><span class="lineNum">      42 </span>            :     parser.add_argument(</a>
<a name="43"><span class="lineNum">      43 </span>            :         '--show-dir', help='directory where painted images will be saved')</a>
<a name="44"><span class="lineNum">      44 </span>            :     parser.add_argument(</a>
<a name="45"><span class="lineNum">      45 </span>            :         '--gpu_collect',</a>
<a name="46"><span class="lineNum">      46 </span>            :         action='store_true',</a>
<a name="47"><span class="lineNum">      47 </span>            :         help='whether to use gpu to collect results')</a>
<a name="48"><span class="lineNum">      48 </span>            :     parser.add_argument('--tmpdir', help='tmp dir for writing some results')</a>
<a name="49"><span class="lineNum">      49 </span>            :     parser.add_argument(</a>
<a name="50"><span class="lineNum">      50 </span>            :         '--options',</a>
<a name="51"><span class="lineNum">      51 </span>            :         nargs='+',</a>
<a name="52"><span class="lineNum">      52 </span>            :         action=DictAction,</a>
<a name="53"><span class="lineNum">      53 </span>            :         help='override some settings in the used config, the key-value pair '</a>
<a name="54"><span class="lineNum">      54 </span>            :         'in xxx=yyy format will be merged into config file.')</a>
<a name="55"><span class="lineNum">      55 </span>            :     parser.add_argument(</a>
<a name="56"><span class="lineNum">      56 </span>            :         '--metric-options',</a>
<a name="57"><span class="lineNum">      57 </span>            :         nargs='+',</a>
<a name="58"><span class="lineNum">      58 </span>            :         action=DictAction,</a>
<a name="59"><span class="lineNum">      59 </span>            :         default={},</a>
<a name="60"><span class="lineNum">      60 </span>            :         help='custom options for evaluation, the key-value pair in xxx=yyy '</a>
<a name="61"><span class="lineNum">      61 </span>            :         'format will be parsed as a dict metric_options for dataset.evaluate()'</a>
<a name="62"><span class="lineNum">      62 </span>            :         ' function.')</a>
<a name="63"><span class="lineNum">      63 </span>            :     parser.add_argument(</a>
<a name="64"><span class="lineNum">      64 </span>            :         '--show-options',</a>
<a name="65"><span class="lineNum">      65 </span>            :         nargs='+',</a>
<a name="66"><span class="lineNum">      66 </span>            :         action=DictAction,</a>
<a name="67"><span class="lineNum">      67 </span>            :         help='custom options for show_result. key-value pair in xxx=yyy.'</a>
<a name="68"><span class="lineNum">      68 </span>            :         'Check available options in `model.show_result`.')</a>
<a name="69"><span class="lineNum">      69 </span>            :     parser.add_argument(</a>
<a name="70"><span class="lineNum">      70 </span>            :         '--launcher',</a>
<a name="71"><span class="lineNum">      71 </span>            :         choices=['none', 'pytorch', 'slurm', 'mpi'],</a>
<a name="72"><span class="lineNum">      72 </span>            :         default='none',</a>
<a name="73"><span class="lineNum">      73 </span>            :         help='job launcher')</a>
<a name="74"><span class="lineNum">      74 </span>            :     parser.add_argument('--local_rank', type=int, default=0)</a>
<a name="75"><span class="lineNum">      75 </span>            :     parser.add_argument(</a>
<a name="76"><span class="lineNum">      76 </span>            :         '--device',</a>
<a name="77"><span class="lineNum">      77 </span>            :         choices=['cpu', 'cuda'],</a>
<a name="78"><span class="lineNum">      78 </span>            :         default='cuda',</a>
<a name="79"><span class="lineNum">      79 </span>            :         help='device used for testing')</a>
<a name="80"><span class="lineNum">      80 </span>            :     args = parser.parse_args()</a>
<a name="81"><span class="lineNum">      81 </span>            :     if 'LOCAL_RANK' not in os.environ:</a>
<a name="82"><span class="lineNum">      82 </span>            :         os.environ['LOCAL_RANK'] = str(args.local_rank)</a>
<a name="83"><span class="lineNum">      83 </span>            :     return args</a>
<a name="84"><span class="lineNum">      84 </span>            : </a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span><span class="lineNoCov">          0 : def main():</span></a>
<a name="87"><span class="lineNum">      87 </span>            :     args = parse_args()</a>
<a name="88"><span class="lineNum">      88 </span>            : </a>
<a name="89"><span class="lineNum">      89 </span>            :     cfg = mmcv.Config.fromfile(args.config)</a>
<a name="90"><span class="lineNum">      90 </span>            :     if args.options is not None:</a>
<a name="91"><span class="lineNum">      91 </span>            :         cfg.merge_from_dict(args.options)</a>
<a name="92"><span class="lineNum">      92 </span>            :     # set cudnn_benchmark</a>
<a name="93"><span class="lineNum">      93 </span>            :     if cfg.get('cudnn_benchmark', False):</a>
<a name="94"><span class="lineNum">      94 </span>            :         torch.backends.cudnn.benchmark = True</a>
<a name="95"><span class="lineNum">      95 </span>            :     cfg.model.pretrained = None</a>
<a name="96"><span class="lineNum">      96 </span>            :     cfg.data.test.test_mode = True</a>
<a name="97"><span class="lineNum">      97 </span>            : </a>
<a name="98"><span class="lineNum">      98 </span>            :     # init distributed env first, since logger depends on the dist info.</a>
<a name="99"><span class="lineNum">      99 </span>            :     if args.launcher == 'none':</a>
<a name="100"><span class="lineNum">     100 </span>            :         distributed = False</a>
<a name="101"><span class="lineNum">     101 </span>            :     else:</a>
<a name="102"><span class="lineNum">     102 </span>            :         distributed = True</a>
<a name="103"><span class="lineNum">     103 </span>            :         init_dist(args.launcher, **cfg.dist_params)</a>
<a name="104"><span class="lineNum">     104 </span>            : </a>
<a name="105"><span class="lineNum">     105 </span>            :     # build the dataloader</a>
<a name="106"><span class="lineNum">     106 </span>            :     dataset = build_dataset(cfg.data.test)</a>
<a name="107"><span class="lineNum">     107 </span>            :     # the extra round_up data will be removed during gpu/cpu collect</a>
<a name="108"><span class="lineNum">     108 </span>            :     data_loader = build_dataloader(</a>
<a name="109"><span class="lineNum">     109 </span>            :         dataset,</a>
<a name="110"><span class="lineNum">     110 </span>            :         samples_per_gpu=cfg.data.samples_per_gpu,</a>
<a name="111"><span class="lineNum">     111 </span>            :         workers_per_gpu=cfg.data.workers_per_gpu,</a>
<a name="112"><span class="lineNum">     112 </span>            :         dist=distributed,</a>
<a name="113"><span class="lineNum">     113 </span>            :         shuffle=False,</a>
<a name="114"><span class="lineNum">     114 </span>            :         round_up=True)</a>
<a name="115"><span class="lineNum">     115 </span>            : </a>
<a name="116"><span class="lineNum">     116 </span>            :     # build the model and load checkpoint</a>
<a name="117"><span class="lineNum">     117 </span>            :     model = build_classifier(cfg.model)</a>
<a name="118"><span class="lineNum">     118 </span>            :     fp16_cfg = cfg.get('fp16', None)</a>
<a name="119"><span class="lineNum">     119 </span>            :     if fp16_cfg is not None:</a>
<a name="120"><span class="lineNum">     120 </span>            :         wrap_fp16_model(model)</a>
<a name="121"><span class="lineNum">     121 </span>            :     checkpoint = load_checkpoint(model, args.checkpoint, map_location='cpu')</a>
<a name="122"><span class="lineNum">     122 </span>            : </a>
<a name="123"><span class="lineNum">     123 </span>            :     if 'CLASSES' in checkpoint.get('meta', {}):</a>
<a name="124"><span class="lineNum">     124 </span>            :         CLASSES = checkpoint['meta']['CLASSES']</a>
<a name="125"><span class="lineNum">     125 </span>            :     else:</a>
<a name="126"><span class="lineNum">     126 </span>            :         from mmcls.datasets import ImageNet</a>
<a name="127"><span class="lineNum">     127 </span>            :         warnings.simplefilter('once')</a>
<a name="128"><span class="lineNum">     128 </span>            :         warnings.warn('Class names are not saved in the checkpoint\'s '</a>
<a name="129"><span class="lineNum">     129 </span>            :                       'meta data, use imagenet by default.')</a>
<a name="130"><span class="lineNum">     130 </span>            :         CLASSES = ImageNet.CLASSES</a>
<a name="131"><span class="lineNum">     131 </span>            : </a>
<a name="132"><span class="lineNum">     132 </span>            :     if not distributed:</a>
<a name="133"><span class="lineNum">     133 </span>            :         if args.device == 'cpu':</a>
<a name="134"><span class="lineNum">     134 </span>            :             model = model.cpu()</a>
<a name="135"><span class="lineNum">     135 </span>            :         else:</a>
<a name="136"><span class="lineNum">     136 </span>            :             model = MMDataParallel(model, device_ids=[0])</a>
<a name="137"><span class="lineNum">     137 </span>            :         model.CLASSES = CLASSES</a>
<a name="138"><span class="lineNum">     138 </span>            :         show_kwargs = {} if args.show_options is None else args.show_options</a>
<a name="139"><span class="lineNum">     139 </span>            :         outputs = single_gpu_test(model, data_loader, args.show, args.show_dir,</a>
<a name="140"><span class="lineNum">     140 </span>            :                                   **show_kwargs)</a>
<a name="141"><span class="lineNum">     141 </span>            :     else:</a>
<a name="142"><span class="lineNum">     142 </span>            :         model = MMDistributedDataParallel(</a>
<a name="143"><span class="lineNum">     143 </span>            :             model.cuda(),</a>
<a name="144"><span class="lineNum">     144 </span>            :             device_ids=[torch.cuda.current_device()],</a>
<a name="145"><span class="lineNum">     145 </span>            :             broadcast_buffers=False)</a>
<a name="146"><span class="lineNum">     146 </span>            :         outputs = multi_gpu_test(model, data_loader, args.tmpdir,</a>
<a name="147"><span class="lineNum">     147 </span>            :                                  args.gpu_collect)</a>
<a name="148"><span class="lineNum">     148 </span>            : </a>
<a name="149"><span class="lineNum">     149 </span>            :     rank, _ = get_dist_info()</a>
<a name="150"><span class="lineNum">     150 </span>            :     if rank == 0:</a>
<a name="151"><span class="lineNum">     151 </span>            :         if args.metrics:</a>
<a name="152"><span class="lineNum">     152 </span>            :             results = dataset.evaluate(outputs, args.metrics,</a>
<a name="153"><span class="lineNum">     153 </span>            :                                        args.metric_options)</a>
<a name="154"><span class="lineNum">     154 </span>            :             for k, v in results.items():</a>
<a name="155"><span class="lineNum">     155 </span>            :                 print(f'\n{k} : {v:.2f}')</a>
<a name="156"><span class="lineNum">     156 </span>            :         else:</a>
<a name="157"><span class="lineNum">     157 </span>            :             warnings.warn('Evaluation metrics are not specified.')</a>
<a name="158"><span class="lineNum">     158 </span>            :             scores = np.vstack(outputs)</a>
<a name="159"><span class="lineNum">     159 </span>            : </a>
<a name="160"><span class="lineNum">     160 </span>            : </a>
<a name="161"><span class="lineNum">     161 </span>            :             # to do, get results</a>
<a name="162"><span class="lineNum">     162 </span>            :             if args.confidenceScoresOut:</a>
<a name="163"><span class="lineNum">     163 </span>            :                 print(&quot;saving confidence scores to &quot;)</a>
<a name="164"><span class="lineNum">     164 </span>            :                 with open(args.confidenceScoresOut, 'a') as outfile:</a>
<a name="165"><span class="lineNum">     165 </span>            :                         json.dump(scores.tolist(), outfile)</a>
<a name="166"><span class="lineNum">     166 </span>            :                 print(args.confidenceScoresOut);</a>
<a name="167"><span class="lineNum">     167 </span>            : </a>
<a name="168"><span class="lineNum">     168 </span>            : </a>
<a name="169"><span class="lineNum">     169 </span>            : </a>
<a name="170"><span class="lineNum">     170 </span>            :             pred_score = np.max(scores, axis=1)</a>
<a name="171"><span class="lineNum">     171 </span>            :             pred_label = np.argmax(scores, axis=1)</a>
<a name="172"><span class="lineNum">     172 </span>            :             pred_class = [CLASSES[lb] for lb in pred_label]</a>
<a name="173"><span class="lineNum">     173 </span>            :             results = {</a>
<a name="174"><span class="lineNum">     174 </span>            :                 'pred_score': pred_score,</a>
<a name="175"><span class="lineNum">     175 </span>            :                 'pred_label': pred_label,</a>
<a name="176"><span class="lineNum">     176 </span>            :                 'pred_class': pred_class</a>
<a name="177"><span class="lineNum">     177 </span>            :             }</a>
<a name="178"><span class="lineNum">     178 </span>            :             if not args.out:</a>
<a name="179"><span class="lineNum">     179 </span>            :                 print('\nthe predicted result for the first element is '</a>
<a name="180"><span class="lineNum">     180 </span>            :                       f'pred_score = {pred_score[0]:.2f}, '</a>
<a name="181"><span class="lineNum">     181 </span>            :                       f'pred_label = {pred_label[0]} '</a>
<a name="182"><span class="lineNum">     182 </span>            :                       f'and pred_class = {pred_class[0]}. '</a>
<a name="183"><span class="lineNum">     183 </span>            :                       'Specify --out to save all results to files.')</a>
<a name="184"><span class="lineNum">     184 </span>            :     if args.out and rank == 0:</a>
<a name="185"><span class="lineNum">     185 </span>            :         print(f'\nwriting results to {args.out}')</a>
<a name="186"><span class="lineNum">     186 </span>            :         mmcv.dump(results, args.out)</a>
<a name="187"><span class="lineNum">     187 </span>            : </a>
<a name="188"><span class="lineNum">     188 </span>            : </a>
<a name="189"><span class="lineNum">     189 </span>            : if __name__ == '__main__':</a>
<a name="190"><span class="lineNum">     190 </span>            :     main()</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
